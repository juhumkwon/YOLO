{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORAfUcNpAwQ5ZjSrY7fKRT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/YOLO/blob/main/yolo(%EC%9D%B4%EB%AF%B8%EC%A7%80%2C%20%EB%8F%99%EC%98%81%EC%83%81%20%EC%B6%94%EB%A1%A0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGfS2Z1VAruw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5c17ac-e8ed-422d-833f-24aeeac8e7b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['Colab Notebooks', 'Data', '20241115_171806.jpg', '20241115_171800.jpg', '20241115_140203.jpg', '20241112_102319.jpg', '20241112_102259.jpg', '20241112_090619.jpg', '20241111_161500.jpg', '20241118_094841.jpg', '20241118_094831.jpg', '1731241210669-10.jpg', '1731241210669-9.jpg', '1731241210669-7.jpg', '1731241210669-6.jpg', '1731241210669-5.jpg', '1731241210669-4.jpg', '1731241210669-2.jpg', '1731241210669-1.jpg', '1731241210669-0.jpg', 'bcc81cd5847d441a677447774c72869d6b80a8d4aad29d6b014f66d68462b423.jpg', '4c22476737e90f67f16ec48fd3734708b95f700a359c4c6f1fd103c53fba49ab.jpg', 'ab097390cafe39a0a56a760fc726719676d117e909dfebeca172b0a052be4226.jpg', '9d1994da022791ce36f69e2d8dd1cddc88385fb2c64690e91deb2197ca3c2c3a.jpg', 'fa4b1daaa4fac6aacbbbf1033bd5eefaaa22f787b8d4b6daff99745f3664281e.jpg', '380e8d5db0dac8d628dc4c21266b0565457e1693fd7fccab3c140c284398ac13.jpg', 'cad915491972c69991669f3f82201c17dc14b469e3b2bba9ed0cc6a6b18c3c08.jpg', 'f2ddbe3a2198060f6cab6bf4df2e293ea13ced47ff5a8a948408d6887952f1e6.jpg', '0472f037dc7a4751d6d62144eb9e68b93eb686683270114d2938d084f8bbaaeb.jpg', '4296c9bca10b315cd61c628555ec93ba0af1ec0a082062bd3078270aeb1dccf6.jpg', 'da6e0114c66c2136ab9cdd9496ef72cc0dd6414b615bca54a06ad7d0a7252188.jpg', 'fb99290ed5b87506bb4df2b2a7222bd333d5b0c2387d388fda65b3b38a9cbc7b.jpg', 'af554d7463043751b33afdd4d7e6c79d03ea5d4978504a0458666c9c490b395c.jpg', '704ab04dddf3ced4e766f7156494714d9e6786f2348a284f1228c185f716c62e.jpg', '20241110_134154.jpg', '20241110_134145.jpg', '20241110_130637.jpg', '20241110_130626.jpg', '20241110_130252.jpg', '20241110_130250.jpg', '20241110_130243.jpg', '20241110_130152.jpg', 'd820a0e1322b3bf853b8b7e20320884f81e02d09d870cc2329cfc4d3f76aee1d.jpg', '2c7a8bcda6252d4f92533f223b03bf807713dcdd95de90aa4fb526c29c892fb8.jpg', '9cf1857d24248aa454fb74e48f9ad591fdbd0a31abeda2d507afb8cffa56cf4e.jpg', '20241027_141317.jpg', '20241027_121455.jpg', '20241027_121446.jpg', '20241027_121444.jpg', '20241027_121442.jpg', '20241027_121436.jpg', '20241027_121430.jpg', '20241027_121037.jpg', '20241027_120938.jpg', '20241027_120912.jpg', '20241027_120735.jpg', '20241027_120723.jpg', '20241027_120425.jpg', '20241027_120421.jpg', '20241027_112311.jpg', '20241027_112308.jpg', '20241027_112305.jpg', '20241027_112254.jpg', '20241027_112248.jpg', '20241027_111818.jpg', '20241027_111814.jpg', '20241027_111745.jpg', '20241027_094319.jpg', '20241027_094029.jpg', 'b45165cf0b20b78b7c0b819c0d5586be9f79c35d7284c2618ca6926d683428cc.jpg', '20241025_004603.jpg', '20241024_121823.jpg', '5054bbbd32c1e900dccef76e93048dead5c4180f5fb00263a96b27e8f494fc75.jpg', '83963b68e98f7d8352f8732140c410f806e61fb7dbca5f1e9d3639689c6d7d3c.jpg', '20241016_114446.jpg', '20241016_114229.jpg', '20241007_145955.jpg', '20241007_145857.jpg', 'a66bc0e083f2e5a4de618a23d66bafe3de3380b2f7200b0440166bdb4959ad26.jpg', 'de31459166e10a79673a53e4668bc1689a8c4b74885eaeacb6fc22f3958458c7.jpg', '5d05367e45b1646954b680eb4a439ddb01e638742f75c062e15972726d0f968f.jpg', '20241005_180647.jpg', '20241005_180613.jpg', '1725681801849-1.jpg', '1725681801849-0.jpg', '1721911534719.jpg', '1715151779055.jpg', 'BandPhoto_2024_04_27_20_51_53.jpg', 'BandPhoto_2024_04_23_09_41_59.jpg', '1712314268148.jpg', '1703744635973.jpg', '1703744513761.jpg', '1702722768172.jpg', '1702129244048.jpg', '1700123002662.jpg', '1700122999675.jpg', '1698919668769.jpg', '1698919668665.jpg', '1694911286004.jpg', '1694911285939.jpg', '1694911285505.jpg', '1694911285153.jpg', '1694911285109.jpg', '1694911285076.jpg', '1694911285039.jpg', '1694911284959.jpg', '1694911284826.jpg', '1693045180678.jpg', '1690371490255.jpg', '1690371490116.jpg', '1690371490058.jpg', '1690371489973.jpg', '1690371489921.jpg', '1690371489868.jpg', '1690371489770.jpg', 'IMG_20230707_224952_549.jpg', '1684830671337.jpg', '1684815504870.jpg', '1684813475147.jpg', '1684830597450.jpg', '1684830585537.jpg', '1684830539997.jpg', '1684830528883.jpg', '1638256907717-7.jpg', '1638256907717-4.jpg', '1650164846814-4.jpg', '1650164846814-2.jpg', '1656042556630-0.jpg', '1638256907717-6.jpg', '1638256907717-5.jpg', '1638256907717-11.jpg', '1638256907717-10.jpg', '1650164846814-3.jpg', '1658456869960.jpg', '1664071276948.jpg', '1664071277042.jpg', '1664071277090.jpg', '1664071289344.jpg', '1664095553664.jpg', '1664095553742.jpg', '1664095553797.jpg', '1668290984408.jpg', '1669238790611.jpg', '1669238795744.jpg', '1680424318765.jpg', '1680424318850.jpg', '1680424318890.jpg', '1680424318951.jpg', '1680424319000.jpg', '1680424319049.jpg', '1680438696517.jpg', '1680438696602.jpg', '1680438696652.jpg', '1680438696700.jpg', '1682154339959.jpg', '1682154339893.jpg', '1682154339806.jpg', '1681037073581.jpg', '1681037073696.jpg', 'yolov5']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "file_path = '/content/drive/My Drive'\n",
        "print(os.listdir(file_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy pandas opencv-python\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!cd yolov5\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "Zc6f0YB-BJwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5 전이 학습\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# YOLOv5 라이브러리 가져오기\n",
        "from yolov5 import train\n",
        "\n",
        "# 커스텀 데이터셋 경로\n",
        "DATASET_YAML = \"path/to/your/dataset.yaml\"  # YAML 파일 경로 (예: 'data/coco128.yaml')\n",
        "PRETRAINED_MODEL = \"yolov5s.pt\"  # 사전 학습된 모델 (yolov5s, yolov5m 등)\n",
        "\n",
        "# 저장 경로 설정\n",
        "SAVE_DIR = \"runs/train_custom\"  # 학습 결과 저장 경로\n",
        "\n",
        "# 학습 파라미터 설정\n",
        "EPOCHS = 50  # 학습 반복 횟수\n",
        "BATCH_SIZE = 16  # 배치 크기\n",
        "IMG_SIZE = 640  # 입력 이미지 크기\n",
        "\n",
        "def main():\n",
        "    # YOLOv5 훈련 실행\n",
        "    train.run(\n",
        "        data=DATASET_YAML,\n",
        "        weights=PRETRAINED_MODEL,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        img_size=IMG_SIZE,\n",
        "        project=SAVE_DIR,\n",
        "        name=\"exp\",\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "c4xlWIWBBIGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 준비\n",
        "# 데이터셋은 YOLO 포맷(이미지와 라벨 파일)이어야 하며, dataset.yaml 파일로 정의해야 합니다.\n",
        "\n",
        "train: ../data/train/images  # 학습 이미지 경로\n",
        "val: ../data/val/images      # 검증 이미지 경로\n",
        "\n",
        "# 클래스 이름 (예: 2개 클래스인 경우)\n",
        "names:\n",
        "  0: cat\n",
        "  1: dog\n"
      ],
      "metadata": {
        "id": "HBVQUIArBxhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론 코드\n",
        "# YOLOv5로 학습된 모델을 이용하여 추론하는 간단한 예제 프로그램을 아래에 제공합니다.\n",
        "# 이 코드는 학습된 모델(best.pt)을 사용하여 이미지나 동영상에서 객체를 감지합니다.\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습된 모델 경로\n",
        "MODEL_PATH = \"runs/train_custom/exp/weights/best.pt\"  # 학습된 모델 파일 경로\n",
        "IMAGE_PATH = \"path/to/your/image.jpg\"  # 추론할 이미지 경로\n",
        "VIDEO_PATH = \"path/to/your/video.mp4\"  # 추론할 동영상 경로 (옵션)\n",
        "\n",
        "# 모델 로드\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_PATH)  # 사용자 정의 모델 로드\n",
        "\n",
        "def infer_image(image_path):\n",
        "    # 이미지 로드 및 추론\n",
        "    results = model(image_path)\n",
        "\n",
        "    # 추론 결과 시각화\n",
        "    results.render()  # 이미지 위에 박스와 라벨 그리기\n",
        "    for img in results.imgs:\n",
        "        plt.imshow(img[..., ::-1])  # BGR -> RGB로 변환\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "def infer_video(video_path, output_path=\"output.mp4\"):\n",
        "    # 동영상 로드\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # MP4 코덱\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # 추론 수행\n",
        "        results = model(frame)\n",
        "\n",
        "        # 추론 결과 이미지 위에 그리기\n",
        "        for box in results.xyxy[0]:\n",
        "            x1, y1, x2, y2, conf, cls = map(int, box[:6])\n",
        "            label = f\"{model.names[cls]} {conf:.2f}\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        out.write(frame)  # 결과 저장\n",
        "        cv2.imshow(\"YOLOv5 Inference\", frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 이미지 추론\n",
        "    infer_image(IMAGE_PATH)\n",
        "\n",
        "    # 동영상 추론 (옵션)\n",
        "    # infer_video(VIDEO_PATH, output_path=\"output_inference.mp4\")\n"
      ],
      "metadata": {
        "id": "kP9r1SQ4B7l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# 모델 경로와 이미지 경로 설정\n",
        "MODEL_PATH = \"/content/drive/My Drive/yolov5/runs/train/yolov5s_results/weights/best.pt\"\n",
        "IMAGE_PATH = \"/content/drive/My Drive/Data/yt-wfBfQzHF5K0-0027_jpg.rf.11f46c5dedd8c93d42ed4e03c80939c8.jpg\"\n",
        "\n",
        "# 모델 로드\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_PATH)\n",
        "model.conf = 0.1  # 신뢰도 임계값 설정\n",
        "\n",
        "def infer_image(image_path):\n",
        "    # 이미지 로드 및 RGB 변환\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR -> RGB 변환\n",
        "\n",
        "    # 추론 실행\n",
        "    results = model(image)\n",
        "\n",
        "    # 감지된 객체 출력 (Pandas 형식)\n",
        "    print(\"Detection results:\")\n",
        "    print(results.pandas().xyxy[0])  # 감지된 객체 정보 출력\n",
        "\n",
        "    # 렌더링된 이미지 확인\n",
        "    print(\"Rendered image available:\", len(results.ims) > 0)  # 렌더링된 이미지 확인\n",
        "\n",
        "    # 추론 결과 시각화\n",
        "    results.render()  # 렌더링된 이미지에 바운딩 박스 그리기\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # BGR -> RGB 변환 후 이미지 표시\n",
        "    plt.imshow(results.ims[0][..., ::-1])  # BGR -> RGB 변환\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Detection Results: Burung Murai Batu\")\n",
        "    plt.show()\n",
        "\n",
        "    # 렌더링된 이미지를 PIL 형식으로 변환 후 저장\n",
        "    result_image = Image.fromarray(results.ims[0])  # 렌더링된 이미지를 PIL 형식으로 변환\n",
        "    result_image.save(\"output.jpg\")  # 결과 이미지를 파일로 저장\n",
        "    print(\"결과 이미지가 'output.jpg'로 저장되었습니다.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    infer_image(IMAGE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC0Kbt1OCFbX",
        "outputId": "8db32b19-dd80-4151-a3fb-75c87c41d2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2025-1-25 Python-3.11.11 torch-2.5.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection results:\n",
            "         xmin        ymin        xmax        ymax  confidence  class  \\\n",
            "0  264.794006  160.803864  456.919556  401.781219    0.583673      3   \n",
            "\n",
            "                name  \n",
            "0  Burung Murai Batu  \n",
            "Rendered image available: True\n",
            "결과 이미지가 'output.jpg'로 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Data/bird.jpg\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"파일이 존재합니다: {file_path}\")\n",
        "else:\n",
        "    print(f\"파일이 존재하지 않습니다: {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7B1IKz-PJ0X",
        "outputId": "42afd6ab-c270-46b5-b462-02cbe7a8f48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 존재합니다: /content/drive/My Drive/Data/bird.jpg\n"
          ]
        }
      ]
    }
  ]
}